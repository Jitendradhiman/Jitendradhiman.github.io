


<title>Jitendra Kumar Dhiman</title>
<link href="./styles/styleFile.css" rel="stylesheet" type="text/css">
</head>


<body>

<div id="header">
  <div id="name"> Jitendra Kumar Dhiman
  </div>
<br clear="all">

  <div id="credentials">
  Ph.D. Scholar @ Spectrum Lab, Department of Electrical Engineering, Indian Institute of Science<br>
  </div>
</div>  <!-- End header div -->

<br>
<div id="main">
<center>
<table>
<tbody><tr>
<td align="center" valign="bottom">
<h4>
| <a href="./index.html">Home</a> |
<a href="./research_interests.html">Research</a> |
<!--<a href="./coursework.html">Coursework</a> |--> 
<a href="./publications.html">Publications</a> |
<a href="./CV.pdf">CV</a> |
<a href="./talks.html">Presentations</a> |
<a href="./contactme.html">Contact me</a> |
<a href="./Resources.html">Resources</a> |
</h4>
</td>
</tr>
</tbody></table> <br>
</center>

<div id = "right">
<img src="./images/myphoto1.jpg" alt="random image" width="230" align="right">
</div>

<div id="left">
<h2>Research Interests</h2>
<p>Speech processing and machine learning. </p>
<h2>Research Work</h2>
<p>We develop a novel two-dimensional (2-D) framework for speech analysis.
In contrast to one-dimensional (1-D) short-time processing of speech signals, the proposed 2-D analysis of the speech signals is applied jointly along time and frequency dimensions.
We construct a narrowband speech spectrogram and divide it into smaller local spectro-temporal patches, where each patch is modelled by using a 2-D amplitude- and frequency modulated cosine carrier signal. The amplitude (AM) and frequency modulation (FM) components are separated using a 2-D demodulation technique which employs a new tool: <i>the complex Riesz transform</i>.
<p>This highly accurate spectrogram demodulation technique gives 2-D AM and FM components which correspond to the vocal-tract filter magnitude response and the 2-D source excitation signal, respectively.</p>
<p>Inspired from the speech production mechanism,  the proposed framework gives several new insights into the speech signal characteristics jointly in the time-frequency plane.
We employ the proposed model for several fundamental speech processing tasks such as pitch estimation, periodic/aperiodic speech separation, voiced/unvoiced speech separation, the time-frequency noise modelling for voiced and unvoiced speech sounds and the estimation of vocal-tract filter magnitude response.
The estimated speech parameters are validated by incorporating them in source-filter theory based vocoders and recently proposed deep-learning based vocoders such as waveNet.
This new class of spectro-temporal algorithms can be highly promising for speech analysis and synthesis.  
</p>

<!--I did my B.E. from Government Engineering College (College of Technology and Engineering), Udaipur, Rajasthan, in Electronics in Communication, 2013.-->

</div>

<div id="footer">

<br clear="all">


<!--<table cellpadding="2">
<tbody><tr>
  <td><i>Last modified on September 09, 2012.</i></td>
</tr>
</tbody></table>-->

</div>

</body></html>
